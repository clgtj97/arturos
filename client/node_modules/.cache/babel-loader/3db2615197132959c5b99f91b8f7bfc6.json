{"ast":null,"code":"// Copyright 2012 Mark Cavage <mcavage@gmail.com> All rights reserved.\n'use strict';\n\nvar sprintf = require('util').format;\n\nvar assert = require('assert-plus');\n\nvar LRU = require('lru-cache');\n\nvar errors = require('restify-errors'); ///--- Globals\n\n\nvar TooManyRequestsError = errors.TooManyRequestsError;\nvar MESSAGE = 'You have exceeded your request rate of %s r/s.'; ///--- Helpers\n\n/**\n * @private\n * @function xor\n * @returns {undefined} no return value\n */\n\nfunction xor() {\n  var x = false;\n\n  for (var i = 0; i < arguments.length; i++) {\n    if (arguments[i] && !x) {\n      x = true;\n    } else if (arguments[i] && x) {\n      return false;\n    }\n  }\n\n  return x;\n} ///--- Internal Class (TokenBucket)\n\n/**\n * An implementation of the Token Bucket algorithm.\n *\n * Basically, in network throttling, there are two \"mainstream\"\n * algorithms for throttling requests, Token Bucket and Leaky Bucket.\n * For restify, I went with Token Bucket.  For a good description of the\n * algorithm, see: http://en.wikipedia.org/wiki/Token_bucket\n *\n * In the options object, you pass in the total tokens and the fill rate.\n * Practically speaking, this means \"allow `fill rate` requests/second,\n * with bursts up to `total tokens`\".  Note that the bucket is initialized\n * to full.\n *\n * Also, in googling, I came across a concise python implementation, so this\n * is just a port of that. Thanks http://code.activestate.com/recipes/511490 !\n *\n * @private\n * @class TokenBucket\n * @param {Object} options - contains the parameters:\n *                   - {Number} capacity the maximum burst.\n *                   - {Number} fillRate the rate to refill tokens.\n */\n\n\nfunction TokenBucket(options) {\n  assert.object(options, 'options');\n  assert.number(options.capacity, 'options.capacity');\n  assert.number(options.fillRate, 'options.fillRate');\n  this.tokens = this.capacity = options.capacity;\n  this.fillRate = options.fillRate;\n  this.time = Date.now();\n}\n/**\n * Consume N tokens from the bucket.\n *\n * If there is not capacity, the tokens are not pulled from the bucket.\n *\n * @private\n * @memberof TokenBucket\n * @instance\n * @function consume\n * @param    {Number}  tokens - the number of tokens to pull out.\n * @returns  {Boolean}        true if capacity, false otherwise.\n */\n\n\nTokenBucket.prototype.consume = function consume(tokens) {\n  if (tokens <= this._fill()) {\n    this.tokens -= tokens;\n    return true;\n  }\n\n  return false;\n};\n/**\n * Fills the bucket with more tokens.\n *\n * Rather than do some whacky setTimeout() deal, we just approximate refilling\n * the bucket by tracking elapsed time from the last time we touched the bucket.\n *\n * Simply, we set the bucket size to min(totalTokens,\n *                                       current + (fillRate * elapsed time)).\n *\n * @private\n * @memberof TokenBucket\n * @instance\n * @function _fill\n * @returns  {Number} the current number of tokens in the bucket.\n */\n\n\nTokenBucket.prototype._fill = function _fill() {\n  var now = Date.now(); // reset account for clock drift (like DST)\n\n  if (now < this.time) {\n    this.time = now - 1000;\n  }\n\n  if (this.tokens < this.capacity) {\n    var delta = this.fillRate * ((now - this.time) / 1000);\n    this.tokens = Math.min(this.capacity, this.tokens + delta);\n  }\n\n  this.time = now;\n  return this.tokens;\n}; ///--- Internal Class (TokenTable)\n\n/**\n * Just a wrapper over LRU that supports put/get to store token -> bucket\n * mappings.\n *\n * @private\n * @class TokenTable\n * @param {Object} options -      an options object\n * @param {Number} options.size - size of the LRU\n */\n\n\nfunction TokenTable(options) {\n  assert.object(options, 'options');\n  this.table = new LRU(options.size || 10000);\n}\n/**\n * Puts a value in the token table\n *\n * @private\n * @memberof TokenTable\n * @instance\n * @function put\n * @param {String}      key -   a name\n * @param {TokenBucket} value - a TokenBucket\n * @returns {undefined} no return value\n */\n\n\nTokenTable.prototype.put = function put(key, value) {\n  this.table.set(key, value);\n};\n/**\n * Puts a value in the token table\n *\n * @private\n * @memberof TokenTable\n * @instance\n * @function get\n * @param {String} key - a key\n * @returns {TokenBucket} token bucket instance\n */\n\n\nTokenTable.prototype.get = function get(key) {\n  return this.table.get(key);\n}; ///--- Exported API\n\n/**\n * Creates an API rate limiter that can be plugged into the standard\n * restify request handling pipeline.\n *\n * `restify` ships with a fairly comprehensive implementation of\n * [Token bucket](http://en.wikipedia.org/wiki/Token_bucket), with the ability\n * to throttle on IP (or x-forwarded-for) and username (from `req.username`).\n * You define \"global\" request rate and burst rate, and you can define\n * overrides for specific keys.\n * Note that you can always place this on per-URL routes to enable\n * different request rates to different resources (if for example, one route,\n * like `/my/slow/database` is much easier to overwhlem\n * than `/my/fast/memcache`).\n *\n * If a client has consumed all of their available rate/burst, an HTTP response\n * code of `429`\n * [Too Many Requests]\n * (http://tools.ietf.org/html/draft-nottingham-http-new-status-03#section-4)\n * is returned.\n *\n * This throttle gives you three options on which to throttle:\n * username, IP address and 'X-Forwarded-For'. IP/XFF is a /32 match,\n * so keep that in mind if using it.  Username takes the user specified\n * on req.username (which gets automagically set for supported Authorization\n * types; otherwise set it yourself with a filter that runs before this).\n *\n * In both cases, you can set a `burst` and a `rate` (in requests/seconds),\n * as an integer/float.  Those really translate to the `TokenBucket`\n * algorithm, so read up on that (or see the comments above...).\n *\n * In either case, the top level options burst/rate set a blanket throttling\n * rate, and then you can pass in an `overrides` object with rates for\n * specific users/IPs.  You should use overrides sparingly, as we make a new\n * TokenBucket to track each.\n *\n * On the `options` object ip and username are treated as an XOR.\n *\n * @public\n * @function throttle\n * @throws {TooManyRequestsError}\n * @param {Object} options - required options with:\n * @param {Number} options.burst - burst\n * @param {Number} options.rate - rate\n * @param {Boolean} [options.ip] - ip\n * @param {Boolean} [options.username] - username\n * @param {Boolean} [options.xff] - xff\n * @param {Boolean} [options.setHeaders=false] - Set response headers for rate,\n *                               limit (burst) and remaining.\n * @param {Object} [options.overrides] - overrides\n * @param {Object} options.tokensTable - a storage engine this plugin will\n *                              use to store throttling keys -> bucket mappings.\n *                              If you don't specify this, the default is to\n *                              use an in-memory O(1) LRU, with 10k distinct\n *                              keys.  Any implementation just needs to support\n *                              put/get.\n * @param {Number} [options.maxKeys=10000] - If using the default\n *                              implementation, you can specify how large you\n *                              want the table to be.\n * @returns  {Function} Handler\n * @example\n * <caption>\n * An example options object with overrides:\n * </caption>\n * {\n *   burst: 10,  // Max 10 concurrent requests (if tokens)\n *   rate: 0.5,  // Steady state: 1 request / 2 seconds\n *   ip: true,   // throttle per IP\n *   overrides: {\n *     '192.168.1.1': {\n *       burst: 0,\n *       rate: 0    // unlimited\n *   }\n * }\n */\n\n\nfunction throttle(options) {\n  assert.object(options, 'options');\n  assert.number(options.burst, 'options.burst');\n  assert.number(options.rate, 'options.rate');\n  assert.optionalBool(options.setHeaders, 'options.setHeaders');\n\n  if (!xor(options.ip, options.xff, options.username)) {\n    throw new Error('(ip ^ username ^ xff)');\n  }\n\n  var table = options.tokensTable || new TokenTable({\n    size: options.maxKeys\n  });\n\n  function rateLimit(req, res, next) {\n    var attr;\n    var burst = options.burst;\n    var rate = options.rate;\n\n    if (options.ip) {\n      attr = req.connection.remoteAddress;\n    } else if (options.xff) {\n      attr = req.headers['x-forwarded-for'];\n    } else if (options.username) {\n      attr = req.username;\n    } else {\n      req.log.warn({\n        config: options\n      }, 'Invalid throttle configuration');\n      return next();\n    } // Before bothering with overrides, see if this request\n    // even matches\n\n\n    if (!attr) {\n      return next();\n    } // Check the overrides\n\n\n    if (options.overrides && options.overrides[attr] && options.overrides[attr].burst !== undefined && options.overrides[attr].rate !== undefined) {\n      burst = options.overrides[attr].burst;\n      rate = options.overrides[attr].rate;\n    }\n\n    if (!rate || !burst) {\n      return next();\n    }\n\n    var bucket = table.get(attr);\n\n    if (!bucket) {\n      bucket = new TokenBucket({\n        capacity: burst,\n        fillRate: rate\n      });\n      table.put(attr, bucket);\n    }\n\n    req.log.trace('Throttle(%s): num_tokens= %d', attr, bucket.tokens);\n    var tooManyRequests = !bucket.consume(1); // set throttle headers after consume which changes the remaining tokens\n\n    if (options.setHeaders) {\n      res.header('X-RateLimit-Remaining', Math.floor(bucket.tokens));\n      res.header('X-RateLimit-Limit', burst);\n      res.header('X-RateLimit-Rate', rate);\n    }\n\n    if (tooManyRequests) {\n      req.log.info({\n        address: req.connection.remoteAddress || '?',\n        method: req.method,\n        url: req.url,\n        user: req.username || '?'\n      }, 'Throttling');\n      var msg = sprintf(MESSAGE, rate);\n      return next(new TooManyRequestsError(msg));\n    }\n\n    return next();\n  }\n\n  return rateLimit;\n}\n\nmodule.exports = throttle;","map":null,"metadata":{},"sourceType":"script"}